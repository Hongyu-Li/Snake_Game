{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Snake-Game-Alpha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNb7J4DYfYBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# uninstall older version and install tensorflow 2.0\n",
        "!pip uninstall tensorflow\n",
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "formRyucfARz",
        "colab_type": "text"
      },
      "source": [
        "Please restart the colab so as to make the tf 2.0 be effective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VElE6EnehCK9",
        "colab_type": "code",
        "outputId": "77afee08-d77a-40ce-c726-52a0d824c242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXBO6_7niH-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nYm15zph2Zd",
        "colab_type": "text"
      },
      "source": [
        "## Step 0: Create Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBTxEvj2FREs",
        "colab_type": "text"
      },
      "source": [
        "Here we downloaded our original dataset from [head pose image database](http://www-prima.inrialpes.fr/perso/Gourier/Faces/HPDatabase.html). And only four directions (up, down, left and right) are used to form the dataset of this demo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj4vtDAihSNs",
        "colab_type": "code",
        "outputId": "ab800210-b9bb-428c-de06-1d2e65d4f363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = \"http://www-prima.inrialpes.fr/perso/Gourier/Faces/HeadPoseImageDatabase.tar.gz\"\n",
        "urllib.request.urlretrieve(dataset,'data.tar.gz') "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('data.tar.gz', <http.client.HTTPMessage at 0x7f37f3eabb00>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Xvf8btimM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tar file\n",
        "!mkdir data\n",
        "!mkdir headpose\n",
        "!tar -C ./data -zxvf data.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ8TYZEyjV5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Version 1: create dataset in four directions\n",
        "# def createDataset(input_path, output_path):\n",
        "#   personfolders = listdir(input_path)\n",
        "#   for person in personfolders:\n",
        "#     path = input_path + person\n",
        "#     if isdir(path):\n",
        "#       imagesList = listdir(path)\n",
        "#       for image in imagesList:\n",
        "#         image_path = path + '/' + image\n",
        "#         if image[::-1][:9] == '-90+0.jpg'[::-1]:\n",
        "#             shutil.copy(image_path, output_path + person + 'down.jpg')\n",
        "#         elif image[::-1][:9] == '+0-90.jpg'[::-1]:\n",
        "#             shutil.copy(image_path, output_path + person + 'right.jpg')\n",
        "#         elif image[::-1][:9] == '+0+90.jpg'[::-1]:\n",
        "#             shutil.copy(image_path, output_path + person + 'left.jpg')\n",
        "#         elif image[::-1][:9] == '+90+0.jpg'[::-1]:\n",
        "#             shutil.copy(image_path, output_path + person + 'up.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmLD4fdhSxhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createDataset(input_path, output_path):\n",
        "  personfolders = listdir(input_path)\n",
        "  for person in personfolders:\n",
        "    path = input_path + person\n",
        "    if isdir(path):\n",
        "      imagesList = listdir(path)\n",
        "      for image in imagesList:\n",
        "        image_path = path + '/' + image\n",
        "        if image[::-1][:4] == '.jpg'[::-1]:\n",
        "            image_name = image[::-1][:10][::-1]\n",
        "            tilt = int(re.findall('[+-]{1}[0-9]*',image_name)[0])\n",
        "            pan = int(re.findall('[+-]{1}[0-9]*',image_name)[1])\n",
        "            output_name = output_path + image[::-1][4:][::-1]\n",
        "            if person == 'Front':\n",
        "                shutil.copy(image_path, output_name + 'front.jpg')\n",
        "            else:\n",
        "                if abs(tilt) <= 15 and abs(pan) <= 15:\n",
        "                    shutil.copy(image_path, output_name + 'front.jpg')\n",
        "                elif tilt <= -30 and abs(pan) <= 45:\n",
        "                    shutil.copy(image_path, output_name + 'down.jpg')\n",
        "                elif tilt >= 30 and abs(pan) <= 45:\n",
        "                    shutil.copy(image_path, output_name + 'up.jpg')   \n",
        "                elif (abs(tilt) > 30 and pan < -45) or (abs(tilt) <= 15 and pan < -15):\n",
        "                    shutil.copy(image_path, output_name + 'left.jpg') \n",
        "                elif (abs(tilt) > 30 and pan > 45) or (abs(tilt) <= 15 and pan > 15):\n",
        "                    shutil.copy(image_path, output_name + 'right.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyfTfCqEEYt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "createDataset('./data/','./headpose/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIWY3v9hF9Hn",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Load Images and Pre-process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmb9LDwcLr7H",
        "colab_type": "text"
      },
      "source": [
        "### (a) load images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX1quS9SGOc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def name2label(name):\n",
        "  label_dict = {'front':0, 'up':1, 'down':2, 'left': 3, 'right': 4}\n",
        "  direction = re.findall('[0-9]{1}[a-z]+',name)[0][1:]\n",
        "  return label_dict[direction]\n",
        "\n",
        "def loadImages(path, imgH, imgW):\n",
        "  imagesList = listdir(path)\n",
        "  loadedImages = []\n",
        "  labels = []\n",
        "  for image in imagesList:\n",
        "    img = Image.open(path + image)\n",
        "    img = img.resize((width, height))\n",
        "    loadedImages.append(img)\n",
        "    img_label = name2label(image)\n",
        "    labels.append(img_label) \n",
        "  return loadedImages, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELePiZTmEs4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = 224\n",
        "width = 224\n",
        "\n",
        "images, labels = loadImages('./headpose/', height, width)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ueTg02v736z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # version 1: process images without data augmentation\n",
        "# def preprocess_images(imagesList):\n",
        "#   n =  len(imagesList)\n",
        "#   images_array = np.zeros(shape=(n, width, height, 3), dtype='float32')\n",
        "#   for i in range(n):\n",
        "#     images_array[i,:,:,:] = np.asarray(imagesList[i], dtype='float32')\n",
        "#   images_array = images_array / 127.5 - 1  #refer keras image preprocessing utils(tf mode)\n",
        "#   return images_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXbsJLKd8eY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# images_array = preprocess_images(images_array)\n",
        "# labels_array = np.array(labels_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJoC5gzAy_Id",
        "colab_type": "text"
      },
      "source": [
        "### (b)data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMu46m9VzJ41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_aug(x):\n",
        "  x = np.expand_dims(x,0)\n",
        "  # left-translation with 50px\n",
        "  x1 = tf.image.pad_to_bounding_box(x, 0, 10, 224, 234)\n",
        "  x1 = tf.image.crop_to_bounding_box(x1, 0, 0, 224, 224).numpy()[0]\n",
        "  \n",
        "  # top-translation with 50px\n",
        "  x2 = tf.image.pad_to_bounding_box(x, 10, 0, 234, 224)\n",
        "  x2 = tf.image.crop_to_bounding_box(x2, 0, 0, 224, 224).numpy()[0]\n",
        "  \n",
        "  # right-translation with 50px\n",
        "  x3 = tf.image.pad_to_bounding_box(x, 0, 0, 224, 234)\n",
        "  x3 = tf.image.crop_to_bounding_box(x3, 0, 10, 224, 224).numpy()[0]\n",
        "  \n",
        "  # bottom-translation with 50px\n",
        "  x4 = tf.image.pad_to_bounding_box(x, 0, 0, 234, 224)\n",
        "  x4 = tf.image.crop_to_bounding_box(x4, 10, 0, 224, 224).numpy()[0]\n",
        "  \n",
        "  # add noise\n",
        "  noise = tf.random.normal(shape=tf.shape(x), mean=0.0, stddev=0.25,dtype=tf.float32)\n",
        "  x5 = tf.add(x, noise).numpy()[0]\n",
        "                           \n",
        "  \n",
        "  return [x[0],x1,x2,x3,x4,x5]\n",
        "                           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYb4VtqDMgk1",
        "colab_type": "text"
      },
      "source": [
        "### (c) preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDJK7MnvKZkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_images(imagesList, labels):\n",
        "  n =  len(images)\n",
        "  images_array = []\n",
        "  labels_aug = []\n",
        "  for i in range(n):\n",
        "    thres = np.random.uniform(size=1)\n",
        "    if labels[i] == 0 and thres < 0.7:\n",
        "      images_aug = data_aug(np.asarray(imagesList[i], dtype='float32'))\n",
        "      images_array += images_aug\n",
        "      labels_aug += [labels[i]]*6\n",
        "    elif labels[i] == 1 and thres < 0.5:\n",
        "      images_aug = data_aug(np.asarray(imagesList[i], dtype='float32'))\n",
        "      images_array += images_aug\n",
        "      labels_aug += [labels[i]]*6\n",
        "    elif labels[i] == 2 and thres < 0.5:\n",
        "      images_aug = data_aug(np.asarray(imagesList[i], dtype='float32'))\n",
        "      images_array += images_aug\n",
        "      labels_aug += [labels[i]]*6\n",
        "    elif labels[i] == 3 and thres < 0.3:\n",
        "      images_aug = data_aug(np.asarray(imagesList[i], dtype='float32'))\n",
        "      images_array += images_aug\n",
        "      labels_aug += [labels[i]]*6\n",
        "    elif labels[i] == 4 and thres < 0.3:\n",
        "      images_aug = data_aug(np.asarray(imagesList[i], dtype='float32'))\n",
        "      images_array += images_aug  \n",
        "      labels_aug += [labels[i]]*6\n",
        "  images_array = np.asarray(images_array,dtype='float32') / 127.5 - 1  #refer keras image preprocessing utils(tf mode)\n",
        "  return images_array, labels_aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaHsNp2INQHf",
        "colab_type": "code",
        "outputId": "39b878fc-b06e-477d-c32b-1a5defcbd8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(123)\n",
        "images_array, labels_array = preprocess_images(images, labels)\n",
        "labels_array = np.array(labels_array)\n",
        "print(images_array.shape)"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6348, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pzXJWyGPqhm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc219d2a-bad1-4799-ec0d-0d23a12b532b"
      },
      "source": [
        "np.unique(labels_array,return_counts=True)"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4]), array([1320, 1314, 1290, 1188, 1236]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-amEbtKL0hdU",
        "colab_type": "text"
      },
      "source": [
        "### (d) shuffle dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYCjru2c0jpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_array, labels_array = shuffle(images_array, labels_array, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW78oC7JO2vl",
        "colab_type": "text"
      },
      "source": [
        "### (e) split training and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnIHlYPHOul4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.33, random_state=1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRnyjg_qQ_Am",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk9_q9fYRDt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobile_net = tf.keras.applications.MobileNet(input_shape=(224, 224, 3), include_top=False)\n",
        "mobile_net.trainable=False  #non-trainable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqToC-hwvOzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mobile_net.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgsheSVgka4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = mobile_net.predict(images_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siv6ycGyS1NR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build a model based on mobile_net\n",
        "snake_model= tf.keras.Sequential([ \n",
        "#   tf.keras.layers.Dense(1000,activation='relu',input_shape=(7,7,1024,)),  \n",
        "#   tf.keras.layers.Dense(512,activation='relu',input_shape=(7,7,1024,)),\n",
        "#   tf.keras.layers.Dense(128,activation='relu',input_shape=(7,7,1024,)),  \n",
        "#   tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Flatten(input_shape=(7,7,1024,)),\n",
        "  tf.keras.layers.Dense(1024,activation='relu'),\n",
        "  tf.keras.layers.Dense(512,activation='relu'),\n",
        "  tf.keras.layers.Dense(100,activation='relu'),\n",
        "  tf.keras.layers.Dense(5,activation='softmax')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l_xOioxTn96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "snake_model.compile(optimizer=tf.optimizers.Adam(1e-4), \n",
        "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                  metrics=[\"accuracy\"])\n",
        "history=snake_model.fit(features,labels_array,batch_size=256,epochs=20,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDlcyNjxnsgG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3244022-3e26-4b95-f362-afa1959b3025"
      },
      "source": [
        "pred = snake_model.predict(features)\n",
        "pred_y = np.argmax(pred, axis=1)\n",
        "np.unique(pred_y != labels_array, return_counts=True)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([False,  True]), array([5763,  915]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHEiZQ_ZUJMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.epoch,history.history['loss'],label='train')\n",
        "plt.plot(history.epoch,history.history['val_loss'],'--',label='validation')\n",
        "plt.subplot(122)\n",
        "plt.plot(history.epoch,history.history['accuracy'],label='train')\n",
        "plt.plot(history.epoch,history.history['val_accuracy'],'--',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00JoQzioj1rc",
        "colab_type": "code",
        "outputId": "cf8384fb-5bf3-45b2-c18c-f08d0423dd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# img_test = Image.open('./me/front.jpg')\n",
        "# img_test = img_test.resize((width, height))\n",
        "# img_test = np.asarray(img_test, dtype='float32')\n",
        "# img_test = img_test / 127.5 - 1\n",
        "# img_test = np.expand_dims(img_test,0)\n",
        "# temp = mobile_net.predict(img_test)\n",
        "# snake_model.predict(temp)"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5718588e-01, 8.3859557e-01, 5.2573945e-04, 3.3155931e-04,\n",
              "        3.3612815e-03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y27evM5yXQCL",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHzb1xfKan-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model\n",
        "snake_model.save('./model/model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbzH_BChaWF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp6Gru50VTAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir tfjs_model\n",
        "!tensorflowjs_converter --input_format=keras ./model/model.h5 ./tfjs_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2JKeuzLaDCr",
        "colab_type": "code",
        "outputId": "88e253a5-c7fc-4ec2-8a79-a0521a578984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "!zip -r model.zip ./tfjs_model/"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: tfjs_model/ (stored 0%)\n",
            "  adding: tfjs_model/group1-shard50of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard48of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard6of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard39of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard29of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard41of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard24of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard46of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard13of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard26of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard15of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/model.json (deflated 81%)\n",
            "  adding: tfjs_model/group1-shard45of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard4of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard25of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard49of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard19of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard38of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard42of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard27of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard40of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard43of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard10of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard37of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard2of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard36of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard14of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard47of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard3of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard1of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard5of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard23of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard33of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard17of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard31of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard20of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard32of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard8of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard34of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard16of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard7of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard9of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard18of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard22of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard35of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard30of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard12of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard11of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard28of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard21of50.bin (deflated 8%)\n",
            "  adding: tfjs_model/group1-shard44of50.bin (deflated 8%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0852MkVUwMwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf tfjs_model\n",
        "!rm -rf model\n",
        "!rm -rf model.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2raOP8dqAh7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}